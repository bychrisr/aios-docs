# Gestión de Crisis (Sala de Guerra)

Procedimientos para manejar problemas críticos de producción con AIOS, incluyendo disparadores de escalamiento, flujos de trabajo de hotfix, procedimientos de rollback y patrones de comunicación.

## Condiciones de Activación

Activa el protocolo de sala de guerra cuando ocurra cualquiera de estas condiciones:

- Producción caída o severamente degradada
- Pérdida de datos o brecha de seguridad detectada
- Función crítica de negocio no disponible
- Degradación de rendimiento afectando a la mayoría de los usuarios
- Fallas en cascada a través de servicios

## Clasificación de Severidad

| Severidad | Descripción | Tiempo de Respuesta |
|-----------|-------------|---------------------|
| **P0** | Servicio completamente caído; pérdida de datos | Inmediato (minutos) |
| **P1** | Funcionalidad principal rota; impacto significativo en usuarios | Dentro de 1 hora |
| **P2** | Rendimiento degradado; solución temporal disponible | Dentro de 4 horas |
| **P3** | Problema menor; impacto limitado en usuarios | Siguiente sprint |

Los problemas P0 y P1 activan el protocolo completo de sala de guerra. Los problemas P2 usan una versión expedita. Los problemas P3 siguen el Story Development Cycle estándar.

## Protocolo de Sala de Guerra

### 1. Reunir

Activar agentes clave:

```
@devops  -- Infraestructura y despliegue
@dev     -- Investigación de código y correcciones
@qa      -- Verificación y tests de regresión
```

Para incidentes P0, también involucrar a @architect para análisis a nivel de sistema.

### 2. Triaje

1. Identificar el síntoma (lo que los usuarios ven)
2. Verificar despliegues recientes (`git log --oneline -10`)
3. Verificar el estado de la infraestructura (dashboard del proveedor de hosting, monitoreo)
4. Verificar el estado de servicios externos (APIs de terceros, bases de datos)
5. Correlacionar timing con cambios recientes

### 3. Contención

Aplicar la mitigación más rápida en orden de preferencia:

1. **Rollback** -- Revertir al último despliegue conocido como funcional
2. **Feature Flag** -- Deshabilitar la funcionalidad problemática
3. **Hotfix** -- Cambio mínimo de código para restaurar el servicio

### 4. Flujo de Trabajo de Hotfix

Para hotfixes, usa el Story Development Cycle en modo YOLO:

```
@dev *develop hotfix-{issue}
```

Características del modo YOLO:
- Cero a un prompt (ejecución autónoma)
- Todas las decisiones registradas en `decision-log-hotfix-{issue}.md`
- Omitir creación de historia para problemas P0
- Alcance mínimo: corregir solo el problema inmediato

### 5. Verificar

```
@qa *qa-gate
```

Incluso para hotfixes, verificar que:
- La corrección resuelve el problema reportado
- No se introducen nuevas regresiones
- La funcionalidad principal permanece intacta

### 6. Desplegar

```
@devops *push --expedite
```

El push expedito omite el ciclo completo de revisión y marca el PR para merge inmediato.

### 7. Post-Mortem

Después de la resolución, documentar el incidente:

1. **Cronología** -- Registro cronológico de eventos desde la detección hasta la resolución
2. **Causa raíz** -- Análisis técnico de qué falló y por qué
3. **Impacto** -- Usuarios afectados, duración, impacto en el negocio
4. **Respuesta** -- Qué se hizo y con qué rapidez
5. **Prevención** -- Crear historias para prevenir recurrencia

## Disparadores de Escalamiento

Las siguientes condiciones activan el escalamiento automático:

| Disparador | Origen | Objetivo de Escalamiento |
|------------|--------|--------------------------|
| `max_iterations_reached` | QA Loop (5 iteraciones) | @aios-master |
| `verdict_blocked` | QA gate devuelve BLOCKED | @aios-master |
| `fix_failure` | Corrección de Dev falla después de reintentos | @architect |
| `manual_escalate` | Usuario ejecuta `*escalate-qa-loop` | @aios-master |
| Violación constitucional | Cualquier agente detecta violación | BLOQUEAR hasta resolver |

### Comandos de Escalamiento

```
*escalate-qa-loop     # Forzar escalamiento desde QA loop
*stop-qa-loop         # Pausar y guardar estado
*resume-qa-loop       # Reanudar desde estado guardado
```

## Procedimientos de Rollback

### Rollback de Código

```bash
# Identificar el último commit funcional
git log --oneline -20

# Revertir el/los commit(s) problemáticos
@devops *push   # con commit de revert
```

### Rollback de Base de Datos

Si el problema involucra migraciones de base de datos:
1. Identificar la migración problemática
2. Ejecutar la migración down o aplicar una migración correctiva
3. Verificar la integridad de los datos
4. Nunca eliminar datos de producción sin un respaldo

### Rollback de Infraestructura

Para problemas a nivel de infraestructura, @devops gestiona:
- Revertir configuraciones de despliegue
- Escalar recursos de vuelta a niveles anteriores
- Restaurar desde respaldos si es necesario

## Patrones de Comunicación

### Durante el Incidente

- **Actualizaciones de estado** cada 15-30 minutos para P0/P1
- **Propiedad clara** -- Una persona coordina; los agentes ejecutan
- **Registro de decisiones** -- Cada acción y decisión documentada con marcas de tiempo

### Después de la Resolución

- **Reporte de incidente** -- Compartido dentro de las 24 horas
- **Historias preventivas** -- Creadas en el backlog dentro de 48 horas
- **Actualizaciones de monitoreo** -- Alertas y dashboards actualizados para detectar problemas similares

## Checklist de Prevención

Para reducir la probabilidad de futuras crisis:

- [ ] Tests automatizados cubren rutas críticas
- [ ] Feature flags disponibles para funcionalidades principales
- [ ] Monitoreo y alertas configurados para métricas clave
- [ ] Procedimientos de rollback documentados y probados
- [ ] Estrategia de respaldo de base de datos verificada
- [ ] Contactos y canales de respuesta a incidentes establecidos
